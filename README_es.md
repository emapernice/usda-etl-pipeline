# USDA Crop Insights â€” ETL y AnÃ¡lisis con Python y MySQL

Este proyecto desarrolla un **pipeline ETL completo** para **extraer, transformar y cargar** datos agrÃ­colas desde la **API Quick Stats del USDA** hacia una **base de datos MySQL**, con el objetivo de generar **anÃ¡lisis e insights sobre las tendencias de precios agrÃ­colas** en los distintos estados de EE. UU.

---

## DescripciÃ³n General

- **Objetivo:** Automatizar la recolecciÃ³n y el anÃ¡lisis de estadÃ­sticas agrÃ­colas (por ejemplo, precios de soja o maÃ­z).
- **Fuente de datos:** [USDA NASS Quick Stats API](https://quickstats.nass.usda.gov/api)
- **TecnologÃ­as utilizadas:** Python Â· Pandas Â· SQLAlchemy Â· MySQL Â· Matplotlib
- **Enfoque:** AutomatizaciÃ³n ETL real y anÃ¡lisis exploratorio de datos (EDA)

---

##  Estructura del Proyecto


usda-etl-pipeline/
â”‚
â”œâ”€â”€ config/
â”‚ â”œâ”€â”€ .env # Variables de entorno (no incluidas en git)
â”‚ â”œâ”€â”€ db_config.json.example 
â”‚ â””â”€â”€ api_keys.json.example 
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # Datos JSON originales desde la API
â”‚ â””â”€â”€ processed/ # Archivos CSV limpios listos para cargar
â”‚
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ schema.sql 
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ extract.py     # Descarga datos desde la API del USDA
â”‚ â”œâ”€â”€ transform.py   # Limpia, normaliza y valida los datos
â”‚ â”œâ”€â”€ load.py        # Carga los datos procesados en MySQL
â”‚ â”œâ”€â”€ run_etl.py     # Script principal del pipeline
â”‚ â””â”€â”€ api/
â”‚   â”œâ”€â”€ main.py   
â”‚   â”œâ”€â”€ db.py            
â”‚   â””â”€â”€ routes/
â”‚       â””â”€â”€ prices.py   
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md



âš™ï¸ Instrucciones de InstalaciÃ³n

1 - Clonar este repositorio
git clone https://github.com/tuusuario/usda-crop-insights.git
cd usda-crop-insights

2 - Crear y activar un entorno virtual
python3 -m venv venv
source venv/bin/activate   # En macOS/Linux
venv\Scripts\activate      # En Windows

3 - Instalar dependencias
pip install -r requirements.txt

4 - Configurar las variables de entorno
Crear un archivo .env dentro de la carpeta config/ con el siguiente contenido:
MYSQL_USER=tu_usuario
MYSQL_PASSWORD=tu_contraseÃ±a
MYSQL_HOST=localhost
MYSQL_DATABASE=usda_data
USDA_API_KEY=tu_api_key


5 - Ejecutar el pipeline ETL
python src/run_etl.py


ğŸ“Š Ejemplo de Resultados

DespuÃ©s de ejecutar el ETL, los datos limpios se almacenan en la tabla usda_observations en MySQL.
Esto permite generar consultas y anÃ¡lisis como:

Promedio de precios por cultivo y aÃ±o
VariaciÃ³n interanual de precios
ComparaciÃ³n regional entre estados
Ejemplo de consulta SQL:

SELECT year, commodity_desc, AVG(price) AS precio_promedio
FROM usda_observations
WHERE commodity_desc = 'SOYBEANS'
GROUP BY year, commodity_desc
ORDER BY year;

## API (FastAPI)

Una vez que el pipeline ETL almacena los datos limpios del USDA en la base de datos MySQL, este servicio FastAPI permite consultar los resultados procesados

ğŸ“ˆ Mejoras Futuras

Integrar dashboards visuales con Streamlit o Plotly Dash
Ampliar la cobertura a otros cultivos (trigo, algodÃ³n, maÃ­z, etc.)
Automatizar la ejecuciÃ³n con tareas programadas en CRON


ğŸ‘¨â€ğŸ’» Autor

Emanuel Pernice
Analista de Datos & Desarrollador Python
ğŸ“§ [perniceemanuel@gmail.com]